{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "X,y = lib.generate_circle(samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = params_to_coef(X,y)\n",
    "div = np.transpose(division(X,y,w))\n",
    "big_div = np.ones((1,len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def division(X,y,w):\n",
    "    a = -w[0] / w[1]\n",
    "    Xsvm = a * X[:,0] - w[2] / w[1]\n",
    "    div = np.copy(y)\n",
    "    div.fill(0)\n",
    "    div[X[:,1]>Xsvm] = 1\n",
    "    div = np.transpose(np.reshape(div,(-1,1)))\n",
    "    return div\n",
    "\n",
    "def smallify_dataset(X,y,sep):\n",
    "#     print(sep)\n",
    "    y_left = y[sep==0]\n",
    "    X_left = X[sep==0]\n",
    "    y_right = y[sep==1]\n",
    "    X_right = X[sep==1]\n",
    "    return X_left, y_left,  X_right,  y_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caluculate nearest neighbors\n",
    "def find_nn(X,y,n_neighbors=50,n_most_different=50):\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    ys = y[indices]\n",
    "    Xs = X[indices]\n",
    "    most_different_nn = np.argsort(-np.var(ys,1))[:n_most_different]\n",
    "    most_different_var = -np.sort(-np.var(ys,1))[:n_most_different]\n",
    "    return Xs[most_different_nn],ys[most_different_nn],most_different_var\n",
    "\n",
    "def find_proper_svm(X,y):\n",
    "    Xs,ys,var = find_nn(X,y)\n",
    "    combined_score = []\n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    for i in range(len(ys)):\n",
    "        clf.fit(Xs[i], ys[i])\n",
    "#         print(f'{clf.score(Xs[i],ys[i])} {clf.score(X,y)}')\n",
    "#         plotting_funciton(clf,X,y)\n",
    "        combined_score.append(clf.score(Xs[i], ys[i])*var[i])\n",
    "    am = np.argmax(combined_score)\n",
    "    return clf.fit(Xs[am], ys[am])\n",
    "\n",
    "def params_to_coef(X,y):\n",
    "    svm = find_proper_svm(X,y)\n",
    "    w = np.array([svm.coef_[0][0],svm.coef_[0][1],svm.intercept_[0]])\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]]\n",
      "[[1 2]]\n",
      "[[1 2]]\n",
      "[[1 2]]\n",
      "[[1 2]]\n"
     ]
    }
   ],
   "source": [
    "x = np.matrix([1,2])\n",
    "y = np.repeat(x, 5, axis=0)\n",
    "for row in y:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(st.div[0,:]*np.ones((1,len(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svm_tree:\n",
    "    def __init__(self,X,y,depth=5):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.depth = depth\n",
    "\n",
    "        w = params_to_coef(X,y)\n",
    "        self.big_w = np.array(w)\n",
    "        \n",
    "        #div\n",
    "        self.div = division(X,y,w)\n",
    "        self.big_div = np.ones((1,len(y)))\n",
    "#         self.forward_div()\n",
    "#         self.big_div = np.concatenate((self.big_div,self.div),axis=0)\n",
    "\n",
    "        #run each of the duplicates through svm \n",
    "        \n",
    "        #append div\n",
    "        \n",
    "        #svm parameters\n",
    "#         self.svm_param =  np.zeros((2**n_levels,3)) #maybe delete\n",
    "        \n",
    "    #######################start loop here\n",
    "\n",
    "        for level in range(0, self.depth):\n",
    "            w_row = []\n",
    "            div_row = []\n",
    "            for row in self.div:\n",
    "                if np.std(row):\n",
    "                    X_left, y_left,  X_right,  y_right = smallify_dataset(X,y,row)\n",
    "                \n",
    "                if np.std(y_left):\n",
    "                    wl = params_to_coef(X_left, y_left)\n",
    "                    w_row.append(wl)\n",
    "                    div_row.append(np.multiply(row,division(X,y,wl)))\n",
    "                else: \n",
    "                    w_row.append(np.array([0,0,0]))\n",
    "                    div_row.append(np.multiply((1-row),np.ones((1,len(self.y)))))\n",
    "                    \n",
    "                    \n",
    "                if np.std(y_right):\n",
    "                    wr = params_to_coef(X_right,  y_right)\n",
    "                    w_row.append(wr)\n",
    "                    div_row.append(np.multiply((1-row),division(X,y,wr)))\n",
    "                else: \n",
    "                    w_row.append(np.array([0,0,0]))\n",
    "                    div_row.append(np.multiply((1-row),np.ones((1,len(self.y)))))\n",
    "            w_row = np.array(w_row)\n",
    "#             self.big_w = np.concatenate(self.big_w,w_row) #fix later\n",
    "            self.div = np.squeeze(np.array(div_row),1)\n",
    "\n",
    "                    \n",
    "            self.forward_div()\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            # the routing division at current level\n",
    "#             _decision = decision[:, begin_idx:end_idx, :] # -> [batch_size,2**n_layer,2]\n",
    "#             mu = mu*_decision # -> [batch_size,2**n_layer,2]\n",
    "#             begin_idx = end_idx\n",
    "#             end_idx = begin_idx + 2 ** (n_layer+1)\n",
    "#             # merge left and right nodes to the same layer\n",
    "#             mu = mu.view(x.size(0), -1, 1)\n",
    "#             big_mu = torch.cat((big_mu,mu),1)\n",
    "            \n",
    "    \n",
    "    def forward_div(self):\n",
    "        self.inv_div = 1-self.div\n",
    "        self.div = np.concatenate((self.div, self.inv_div), axis=0)\n",
    "        self.big_div = np.concatenate((self.big_div, self.div), axis=0)\n",
    "        \n",
    "    def node(Xn,yn,node_number,level):\n",
    "        #find proper devision\n",
    "        svm = find_proper_svm(Xn,yn)\n",
    "        #define divider function\n",
    "        self.div[node_number,:] = devision(self.X,self.y,svm)\n",
    "        #calculate SVM over children\n",
    "        X_left, y_left,  X_right,  y_right = smallify_dataset(Xm,ym,div)\n",
    "        node(X_left, y_left,2*node_number,level+1)\n",
    "        node(X_right,  y_right,2*node_number+1,level+1)\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = svm_tree(X,y,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = st.big_div\n",
    "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x, save_flag = False):\n",
    "        if self.prms.feature_map == True:\n",
    "            if x.is_cuda and not self.feature_mask.is_cuda:\n",
    "                self.feature_mask = self.feature_mask.cuda()\n",
    "            feats = torch.mm(x.view(-1,self.feature_mask.size(0)), self.feature_mask)\n",
    "        else:\n",
    "            feats = x\n",
    "\n",
    "        self.d = [self.decision(node(feats)) for node in self.fc]\n",
    "        \n",
    "        self.d = torch.stack(self.d)\n",
    "\n",
    "        decision = torch.cat((self.d,1-self.d),dim=2).permute(1,0,2)\n",
    "        \n",
    "        batch_size = x.size()[0]\n",
    "        mu = x.data.new(x.size(0),1,1).fill_(1.)\n",
    "        big_mu = x.data.new(x.size(0),2,1).fill_(1.)\n",
    "        begin_idx = 1\n",
    "        end_idx = 2\n",
    "        for n_layer in range(0, self.depth):\n",
    "            # mu stores the probability a sample is routed at certain node\n",
    "            # repeat it to be multiplied for left and right routing\n",
    "            mu = mu.repeat(1, 1, 2)\n",
    "            # the routing probability at n_layer\n",
    "            _decision = decision[:, begin_idx:end_idx, :] # -> [batch_size,2**n_layer,2]\n",
    "            mu = mu*_decision # -> [batch_size,2**n_layer,2]\n",
    "            begin_idx = end_idx\n",
    "            end_idx = begin_idx + 2 ** (n_layer+1)\n",
    "            # merge left and right nodes to the same layer\n",
    "            mu = mu.view(x.size(0), -1, 1)\n",
    "            big_mu = torch.cat((big_mu,mu),1)\n",
    "\n",
    "        big_mu = big_mu.view(x.size(0), -1)    \n",
    "        # self.mu_cache.append(big_mu)  \n",
    "        return big_mu #-> [batch size,n_leaf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchcondaef97e2e14a3440b09e2af926cca799cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
